{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Customer Churn\n",
    "\n",
    "# A marketing agency has many customers that use their service to produce ads for the\n",
    "# client/customer websites. They've noticed that they have quite a bit of churn in clients.\n",
    "# They basically randomly assign account managers right now, but want you to create a machine \n",
    "# learning model that will help predict which customers will churn (stop buying their service)\n",
    "# so that they can correctly assign the customers most at risk to churn an account manager. \n",
    "# We will create a classification algorithm that will help classify whether or not a customer \n",
    "# churned. Then the company can test this against incoming data for future customers to predict which customers will churn \n",
    "# and assign them an account manager.\n",
    "\n",
    "# The data is saved as customer_churn.csv. Here are the fields and their definitions:\n",
    "\n",
    "# Name : Name of the latest contact at Company\n",
    "# Age: Customer Age\n",
    "# Total_Purchase: Total Ads Purchased\n",
    "# Account_Manager: Binary 0=No manager, 1= Account manager assigned\n",
    "# Years: Totaly Years as a customer\n",
    "# Num_sites: Number of websites that use the service.\n",
    "# Onboard_date: Date that the name of the latest contact was onboarded\n",
    "# Location: Client HQ Address\n",
    "# Company: Name of Client Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/10/29 15:15:12 WARN Utils: Your hostname, 590-mxl3363mnx resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/10/29 15:15:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/29 15:15:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f7cd0082db0>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"Logistic\").getOrCreate()\n",
    "\n",
    "# Verify Spark session creation\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option('header','true').csv(\"data_logistic.csv\",inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "|              Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|             Company|Churn|\n",
      "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "|   Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|          Harvey LLC|    1|\n",
      "|      Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|          Wilson PLC|    1|\n",
      "|        Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|2016-06-29 06:20:07|1331 Keith Court ...|Miller, Johnson a...|    1|\n",
      "|      Phillip White|42.0|       8010.76|              0| 6.71|     10.0|2014-04-22 12:43:12|13120 Daniel Moun...|           Smith Inc|    1|\n",
      "|     Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|2016-01-19 15:31:15|765 Tricia Row Ka...|          Love-Jones|    1|\n",
      "|   Jessica Williams|48.0|      10356.02|              0| 5.12|      8.0|2009-03-03 23:13:37|6187 Olson Mounta...|        Kelly-Warren|    1|\n",
      "|        Eric Butler|44.0|      11331.58|              1| 5.23|     11.0|2016-12-05 03:35:43|4846 Savannah Roa...|   Reynolds-Sheppard|    1|\n",
      "|      Zachary Walsh|32.0|       9885.12|              1| 6.92|      9.0|2006-03-09 14:50:20|25271 Roy Express...|          Singh-Cole|    1|\n",
      "|        Ashlee Carr|43.0|       14062.6|              1| 5.46|     11.0|2011-09-29 05:47:23|3725 Caroline Str...|           Lopez PLC|    1|\n",
      "|     Jennifer Lynch|40.0|       8066.94|              1| 7.11|     11.0|2006-03-28 15:42:45|363 Sandra Lodge ...|       Reed-Martinez|    1|\n",
      "|       Paula Harris|30.0|      11575.37|              1| 5.22|      8.0|2016-11-13 13:13:01|Unit 8120 Box 916...|Briggs, Lamb and ...|    1|\n",
      "|     Bruce Phillips|45.0|       8771.02|              1| 6.64|     11.0|2015-05-28 12:14:03|Unit 1895 Box 094...|    Figueroa-Maynard|    1|\n",
      "|       Craig Garner|45.0|       8988.67|              1| 4.84|     11.0|2011-02-16 08:10:47|897 Kelley Overpa...|     Abbott-Thompson|    1|\n",
      "|       Nicole Olson|40.0|       8283.32|              1|  5.1|     13.0|2012-11-22 05:35:03|11488 Weaver Cape...|Smith, Kim and Ma...|    1|\n",
      "|     Harold Griffin|41.0|       6569.87|              1|  4.3|     11.0|2015-03-28 02:13:44|1774 Peter Row Ap...|Snyder, Lee and M...|    1|\n",
      "|       James Wright|38.0|      10494.82|              1| 6.81|     12.0|2015-07-22 08:38:40|45408 David Path ...|      Sanders-Pierce|    1|\n",
      "|      Doris Wilkins|45.0|       8213.41|              1| 7.35|     11.0|2006-09-03 06:13:55|28216 Wright Moun...|Andrews, Adams an...|    1|\n",
      "|Katherine Carpenter|43.0|      11226.88|              0| 8.08|     12.0|2006-10-22 04:42:38|Unit 4948 Box 481...|Morgan, Phillips ...|    1|\n",
      "|     Lindsay Martin|53.0|       5515.09|              0| 6.85|      8.0|2015-10-07 00:27:10|69203 Crosby Divi...|      Villanueva LLC|    1|\n",
      "|        Kathy Curry|46.0|        8046.4|              1| 5.69|      8.0|2014-11-06 23:47:14|9569 Caldwell Cre...|Berry, Orr and Ca...|    1|\n",
      "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Names='Cameron Williams', Age=42.0, Total_Purchase=11066.8, Account_Manager=0, Years=7.22, Num_Sites=8.0, Onboard_date=datetime.datetime(2013, 8, 30, 7, 0, 40), Location='10265 Elizabeth Mission Barkerburgh, AK 89518', Company='Harvey LLC', Churn=1) \n",
      "\n",
      "Row(Names='Kevin Mueller', Age=41.0, Total_Purchase=11916.22, Account_Manager=0, Years=6.5, Num_Sites=11.0, Onboard_date=datetime.datetime(2013, 8, 13, 0, 38, 46), Location='6157 Frank Gardens Suite 019 Carloshaven, RI 17756', Company='Wilson PLC', Churn=1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loop through the first two rows of the dataset and print each row \n",
    "\n",
    "for record in df.head(2):\n",
    "    print(record,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/29 15:15:17 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|summary|        Names|              Age|   Total_Purchase|   Account_Manager|            Years|         Num_Sites|            Location|             Company|              Churn|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|  count|          900|              900|              900|               900|              900|               900|                 900|                 900|                900|\n",
      "|   mean|         NULL|41.81666666666667|10062.82403333334|0.4811111111111111| 5.27315555555555| 8.587777777777777|                NULL|                NULL|0.16666666666666666|\n",
      "| stddev|         NULL|6.127560416916251|2408.644531858096|0.4999208935073339|1.274449013194616|1.7648355920350969|                NULL|                NULL| 0.3728852122772358|\n",
      "|    min|   Aaron King|             22.0|            100.0|                 0|              1.0|               3.0|00103 Jeffrey Cre...|     Abbott-Thompson|                  0|\n",
      "|    25%|         NULL|             38.0|          8480.93|                 0|             4.45|               7.0|                NULL|                NULL|                  0|\n",
      "|    50%|         NULL|             42.0|         10041.13|                 0|             5.21|               8.0|                NULL|                NULL|                  0|\n",
      "|    75%|         NULL|             46.0|         11758.69|                 1|             6.11|              10.0|                NULL|                NULL|                  0|\n",
      "|    max|Zachary Walsh|             65.0|         18026.01|                 1|             9.15|              14.0|Unit 9800 Box 287...|Zuniga, Clark and...|                  1|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Names',\n",
       " 'Age',\n",
       " 'Total_Purchase',\n",
       " 'Account_Manager',\n",
       " 'Years',\n",
       " 'Num_Sites',\n",
       " 'Onboard_date',\n",
       " 'Location',\n",
       " 'Company',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format for MLib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Import the necessary modeule for creatin VectorAssembly \n",
    "\n",
    "2) Create a VectorAssembler to assemble selected columns into a feature vector \n",
    "\n",
    "3) Transform the Dataframe using the Vector Assembler to add the 'Features' column \n",
    "\n",
    "4) Select the desired colummns 'Features' and 'Churn' from the transformed Dataframe \n",
    "\n",
    "5) Split the final dataset into training and testing sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['Age','Total_Purchase','Account_Manager', 'Years','Num_Sites'],\n",
    "                            outputCol='Features')\n",
    "\n",
    "\n",
    "output = assembler.transform(df)\n",
    "\n",
    "final_df = output.select('Features','Churn')\n",
    "\n",
    "train_churn,test_churn = final_df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+--------------------+\n",
      "|              Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|             Company|Churn|            Features|\n",
      "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+--------------------+\n",
      "|   Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|2013-08-30 07:00:40|10265 Elizabeth M...|          Harvey LLC|    1|[42.0,11066.8,0.0...|\n",
      "|      Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|2013-08-13 00:38:46|6157 Frank Garden...|          Wilson PLC|    1|[41.0,11916.22,0....|\n",
      "|        Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|2016-06-29 06:20:07|1331 Keith Court ...|Miller, Johnson a...|    1|[38.0,12884.75,0....|\n",
      "|      Phillip White|42.0|       8010.76|              0| 6.71|     10.0|2014-04-22 12:43:12|13120 Daniel Moun...|           Smith Inc|    1|[42.0,8010.76,0.0...|\n",
      "|     Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|2016-01-19 15:31:15|765 Tricia Row Ka...|          Love-Jones|    1|[37.0,9191.58,0.0...|\n",
      "|   Jessica Williams|48.0|      10356.02|              0| 5.12|      8.0|2009-03-03 23:13:37|6187 Olson Mounta...|        Kelly-Warren|    1|[48.0,10356.02,0....|\n",
      "|        Eric Butler|44.0|      11331.58|              1| 5.23|     11.0|2016-12-05 03:35:43|4846 Savannah Roa...|   Reynolds-Sheppard|    1|[44.0,11331.58,1....|\n",
      "|      Zachary Walsh|32.0|       9885.12|              1| 6.92|      9.0|2006-03-09 14:50:20|25271 Roy Express...|          Singh-Cole|    1|[32.0,9885.12,1.0...|\n",
      "|        Ashlee Carr|43.0|       14062.6|              1| 5.46|     11.0|2011-09-29 05:47:23|3725 Caroline Str...|           Lopez PLC|    1|[43.0,14062.6,1.0...|\n",
      "|     Jennifer Lynch|40.0|       8066.94|              1| 7.11|     11.0|2006-03-28 15:42:45|363 Sandra Lodge ...|       Reed-Martinez|    1|[40.0,8066.94,1.0...|\n",
      "|       Paula Harris|30.0|      11575.37|              1| 5.22|      8.0|2016-11-13 13:13:01|Unit 8120 Box 916...|Briggs, Lamb and ...|    1|[30.0,11575.37,1....|\n",
      "|     Bruce Phillips|45.0|       8771.02|              1| 6.64|     11.0|2015-05-28 12:14:03|Unit 1895 Box 094...|    Figueroa-Maynard|    1|[45.0,8771.02,1.0...|\n",
      "|       Craig Garner|45.0|       8988.67|              1| 4.84|     11.0|2011-02-16 08:10:47|897 Kelley Overpa...|     Abbott-Thompson|    1|[45.0,8988.67,1.0...|\n",
      "|       Nicole Olson|40.0|       8283.32|              1|  5.1|     13.0|2012-11-22 05:35:03|11488 Weaver Cape...|Smith, Kim and Ma...|    1|[40.0,8283.32,1.0...|\n",
      "|     Harold Griffin|41.0|       6569.87|              1|  4.3|     11.0|2015-03-28 02:13:44|1774 Peter Row Ap...|Snyder, Lee and M...|    1|[41.0,6569.87,1.0...|\n",
      "|       James Wright|38.0|      10494.82|              1| 6.81|     12.0|2015-07-22 08:38:40|45408 David Path ...|      Sanders-Pierce|    1|[38.0,10494.82,1....|\n",
      "|      Doris Wilkins|45.0|       8213.41|              1| 7.35|     11.0|2006-09-03 06:13:55|28216 Wright Moun...|Andrews, Adams an...|    1|[45.0,8213.41,1.0...|\n",
      "|Katherine Carpenter|43.0|      11226.88|              0| 8.08|     12.0|2006-10-22 04:42:38|Unit 4948 Box 481...|Morgan, Phillips ...|    1|[43.0,11226.88,0....|\n",
      "|     Lindsay Martin|53.0|       5515.09|              0| 6.85|      8.0|2015-10-07 00:27:10|69203 Crosby Divi...|      Villanueva LLC|    1|[53.0,5515.09,0.0...|\n",
      "|        Kathy Curry|46.0|        8046.4|              1| 5.69|      8.0|2014-11-06 23:47:14|9569 Caldwell Cre...|Berry, Orr and Ca...|    1|[46.0,8046.4,1.0,...|\n",
      "+-------------------+----+--------------+---------------+-----+---------+-------------------+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the Model \n",
    "\n",
    "1) Import the necessary modules \n",
    "\n",
    "2) Create a LogisticRegression model \n",
    "\n",
    "3) Fit the model on the training data \n",
    "\n",
    "4) Get the summary of the model's training \n",
    "\n",
    "5) Show the columns from the predictions Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/29 15:15:19 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            Features|Churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[22.0,11254.38,1....|  0.0|[5.41080897883343...|[0.99555185022897...|       0.0|\n",
      "|[28.0,9090.43,1.0...|  0.0|[1.76067672737812...|[0.85329439526511...|       0.0|\n",
      "|[28.0,11204.23,0....|  0.0|[2.04608836924042...|[0.88555177310052...|       0.0|\n",
      "|[28.0,11245.38,0....|  0.0|[4.43799237979913...|[0.98831842795169...|       0.0|\n",
      "|[29.0,5900.78,1.0...|  0.0|[4.70315613992091...|[0.99101484853456...|       0.0|\n",
      "|[29.0,8688.17,1.0...|  1.0|[3.10247531571285...|[0.95699473400818...|       0.0|\n",
      "|[29.0,9378.24,0.0...|  0.0|[5.47642267012038...|[0.99583316369876...|       0.0|\n",
      "|[29.0,10203.18,1....|  0.0|[4.34824521118321...|[0.98723555643862...|       0.0|\n",
      "|[29.0,12711.15,0....|  0.0|[6.23596956687482...|[0.99804609507502...|       0.0|\n",
      "|[29.0,13240.01,1....|  0.0|[7.69729971121337...|[0.99954615446984...|       0.0|\n",
      "|[29.0,13255.05,1....|  0.0|[4.74243767303394...|[0.99135796564660...|       0.0|\n",
      "|[30.0,6744.87,0.0...|  0.0|[4.00474798763058...|[0.98209746070303...|       0.0|\n",
      "|[30.0,7960.64,1.0...|  1.0|[3.38933012984366...|[0.96736940629909...|       0.0|\n",
      "|[30.0,8403.78,1.0...|  0.0|[6.71273121168997...|[0.99878613502286...|       0.0|\n",
      "|[30.0,8874.83,0.0...|  0.0|[3.66021079477970...|[0.97491819286620...|       0.0|\n",
      "|[30.0,10744.14,1....|  1.0|[2.07093286031766...|[0.88804574046388...|       0.0|\n",
      "|[30.0,12788.37,0....|  0.0|[2.8117503607298,...|[0.94330749845698...|       0.0|\n",
      "|[30.0,13473.35,0....|  0.0|[3.05165988949079...|[0.95485413461006...|       0.0|\n",
      "|[31.0,5387.75,0.0...|  0.0|[3.00189222381860...|[0.95265953800483...|       0.0|\n",
      "|[31.0,7073.61,0.0...|  0.0|[3.55945659969384...|[0.97233296310615...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr_churn = LogisticRegression(featuresCol='Features',labelCol='Churn')\n",
    "\n",
    "fit_model = lr_churn.fit(train_churn)\n",
    "\n",
    "training_summary =  fit_model.summary \n",
    "\n",
    "training_summary.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|              Churn|         prediction|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|                608|                608|\n",
      "|   mean|0.17598684210526316|0.14144736842105263|\n",
      "| stddev|  0.381122524576113| 0.3487693740895026|\n",
      "|    min|                0.0|                0.0|\n",
      "|    max|                1.0|                1.0|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_summary.predictions.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            Features|Churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[25.0,9672.03,0.0...|    0|[5.48873923374386...|[0.99588396010275...|       0.0|\n",
      "|[26.0,8787.39,1.0...|    1|[0.74872996662609...|[0.67890190230980...|       0.0|\n",
      "|[26.0,8939.61,0.0...|    0|[7.37366298787875...|[0.99937282839101...|       0.0|\n",
      "|[27.0,8628.8,1.0,...|    0|[6.28703144874340...|[0.99814318011662...|       0.0|\n",
      "|[28.0,8670.98,0.0...|    0|[8.91701316706598...|[0.99986592983105...|       0.0|\n",
      "|[28.0,11128.95,1....|    0|[4.79775059977825...|[0.99181919766736...|       0.0|\n",
      "|[29.0,9617.59,0.0...|    0|[5.14047480224396...|[0.99417917129385...|       0.0|\n",
      "|[29.0,11274.46,1....|    0|[5.10306995810510...|[0.99395866110186...|       0.0|\n",
      "|[30.0,8677.28,1.0...|    0|[4.85655744225170...|[0.99228280688342...|       0.0|\n",
      "|[30.0,10183.98,1....|    0|[3.26835323066737...|[0.96332703893600...|       0.0|\n",
      "|[30.0,10960.52,1....|    0|[2.75620684758341...|[0.94026293361643...|       0.0|\n",
      "|[30.0,11575.37,1....|    1|[4.54317545096114...|[0.98947244124119...|       0.0|\n",
      "|[31.0,5304.6,0.0,...|    0|[3.89845401973793...|[0.98012960777329...|       0.0|\n",
      "|[31.0,10182.6,1.0...|    0|[5.36201930429689...|[0.99533048355203...|       0.0|\n",
      "|[31.0,11743.24,0....|    0|[7.74875223700333...|[0.99956890558191...|       0.0|\n",
      "|[31.0,12264.68,1....|    0|[4.04019650592264...|[0.98271018255530...|       0.0|\n",
      "|[32.0,5756.12,0.0...|    0|[4.82297553468905...|[0.99202135102638...|       0.0|\n",
      "|[32.0,6367.22,1.0...|    0|[3.21998180553871...|[0.96157934231860...|       0.0|\n",
      "|[32.0,7896.65,0.0...|    0|[4.01424046231326...|[0.98226359622412...|       0.0|\n",
      "|[32.0,8011.38,0.0...|    0|[2.26025680267266...|[0.90553160129647...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "pre_and_label = fit_model.evaluate(test_churn)\n",
    "\n",
    "# Show the predictions made on the test dataset\n",
    "pre_and_label.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|              Churn|         prediction|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|                292|                292|\n",
      "|   mean|0.14726027397260275|0.13013698630136986|\n",
      "| stddev| 0.3549735395935993|0.33703168868392885|\n",
      "|    min|                  0|                0.0|\n",
      "|    max|                  1|                1.0|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_and_label.predictions.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Results \n",
    "\n",
    "1) Import Evaluation module \n",
    "\n",
    "2) Create a BinaryClassification Evaluator specifying the raw prediction and label columns \n",
    "\n",
    "3) Calculate the AUC by evaluating the predictions \n",
    "\n",
    "4) Display the calculated AUC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7509573176426637"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Create a BinaryClassificationEvaluator specifying the raw prediction and label columns\n",
    "churn_evl = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Churn')\n",
    "\n",
    "# Calculate the AUC by evaluating the predictions\n",
    "AUC = churn_evl.evaluate(pre_and_label.predictions)\n",
    "\n",
    "# Display the calculated AUC\n",
    "AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
