{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840628 sha256=6e65fe8bb04ca06abbc61e254af494c8cfbe15f70a2477de5ac2c0fb5f3c4bec\n",
      "  Stored in directory: /home/karan/.cache/pip/wheels/07/a0/a3/d24c94bf043ab5c7e38c30491199a2a11fef8d2584e6df7fb7\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A large technology have been hacked! Luckily their engineers have grabbed valuable data about the hacks, including \n",
    "# information like session time,locations, wpm typing speed, etc. The engineer relates to you what she has\n",
    "# been able to figure out so far, she has been able to grab meta data of each session that the hackers used to \n",
    "# connect to their servers. These are the features of the data:\n",
    "\n",
    "#     'Session_Connection_Time': How long the session lasted in minutes\n",
    "#     'Bytes Transferred': Number of MB transferred during session\n",
    "#     'Kali_Trace_Used': Indicates if the hacker was using Kali Linux\n",
    "#     'Servers_Corrupted': Number of server corrupted during the attack\n",
    "#     'Pages_Corrupted': Number of pages illegally accessed\n",
    "#     'Location': Location attack came from (Probably useless because the hackers used VPNs)\n",
    "#     'WPM_Typing_Speed': Their estimated typing speed based on session logs.\n",
    "        \n",
    "# The technology firm has 3 potential hackers that perpetrated the attack. Their certain of the first two hackers but\n",
    "# they aren't very sure if the third hacker was involved or not. We want to figure out whether or not the third \n",
    "# suspect had anything to do with the attacks, or was it just two hackers?\n",
    "\n",
    "# One last key fact, the forensic engineer knows that the hackers trade off attacks. Meaning they should each have \n",
    "# roughly the same amount of attacks. For example if there were 100 total attacks, then in a 2 hacker situation each\n",
    "# should have about 50 hacks, in a three hacker situation each would have about 33 hacks. The engineer believes this \n",
    "# is the key element to solving this, but doesn't know how to distinguish this unlabeled data into groups of hackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/10/28 08:19:58 WARN Utils: Your hostname, 590-mxl3363mnx resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/10/28 08:19:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/28 08:19:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f210c40ac00>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"Practise\").getOrCreate()\n",
    "\n",
    "# Verify Spark session creation\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option('header','true').csv(\"data_kmean.csv\",inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+\n",
      "|Session_Connection_Time|Bytes Transferred|Kali_Trace_Used|Servers_Corrupted|Pages_Corrupted|            Location|WPM_Typing_Speed|\n",
      "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+\n",
      "|                    8.0|           391.09|              1|             2.96|            7.0|            Slovenia|           72.37|\n",
      "|                   20.0|           720.99|              0|             3.04|            9.0|British Virgin Is...|           69.08|\n",
      "|                   31.0|           356.32|              1|             3.71|            8.0|             Tokelau|           70.58|\n",
      "|                    2.0|           228.08|              1|             2.48|            8.0|             Bolivia|            70.8|\n",
      "|                   20.0|            408.5|              0|             3.57|            8.0|                Iraq|           71.28|\n",
      "|                    1.0|           390.69|              1|             2.79|            9.0|    Marshall Islands|           71.57|\n",
      "|                   18.0|           342.97|              1|              5.1|            7.0|             Georgia|           72.32|\n",
      "|                   22.0|           101.61|              1|             3.03|            7.0|         Timor-Leste|           72.03|\n",
      "|                   15.0|           275.53|              1|             3.53|            8.0|Palestinian Terri...|           70.17|\n",
      "|                   12.0|           424.83|              1|             2.53|            8.0|          Bangladesh|           69.99|\n",
      "|                   15.0|           249.09|              1|             3.39|            9.0|Northern Mariana ...|           70.77|\n",
      "|                   32.0|           242.48|              0|             4.24|            8.0|            Zimbabwe|           67.93|\n",
      "|                   23.0|           514.54|              0|             3.18|            8.0|         Isle of Man|           68.56|\n",
      "|                    9.0|           284.77|              0|             3.12|            9.0|Sao Tome and Prin...|           70.82|\n",
      "|                   27.0|           779.25|              1|             2.37|            8.0|              Greece|           72.73|\n",
      "|                   12.0|           307.31|              1|             3.22|            7.0|     Solomon Islands|           67.95|\n",
      "|                   21.0|           355.94|              1|              2.0|            7.0|       Guinea-Bissau|            72.0|\n",
      "|                   10.0|           372.65|              0|             3.33|            7.0|        Burkina Faso|           69.19|\n",
      "|                   20.0|           347.23|              1|             2.33|            7.0|            Mongolia|           70.41|\n",
      "|                   22.0|           456.57|              0|             1.52|            8.0|             Nigeria|           69.35|\n",
      "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Session_Connection_Time: double (nullable = true)\n",
      " |-- Bytes Transferred: double (nullable = true)\n",
      " |-- Kali_Trace_Used: integer (nullable = true)\n",
      " |-- Servers_Corrupted: double (nullable = true)\n",
      " |-- Pages_Corrupted: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- WPM_Typing_Speed: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Summary Statistics for the columns in Dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/28 08:37:22 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------------------+------------------+-----------------+------------------+-----------+------------------+\n",
      "|summary|Session_Connection_Time| Bytes Transferred|   Kali_Trace_Used|Servers_Corrupted|   Pages_Corrupted|   Location|  WPM_Typing_Speed|\n",
      "+-------+-----------------------+------------------+------------------+-----------------+------------------+-----------+------------------+\n",
      "|  count|                    334|               334|               334|              334|               334|        334|               334|\n",
      "|   mean|     30.008982035928145| 607.2452694610777|0.5119760479041916|5.258502994011977|10.838323353293413|       NULL|57.342395209580864|\n",
      "| stddev|     14.088200614636158|286.33593163576757|0.5006065264451406| 2.30190693339697|  3.06352633036022|       NULL| 13.41106336843464|\n",
      "|    min|                    1.0|              10.0|                 0|              1.0|               6.0|Afghanistan|              40.0|\n",
      "|    25%|                   18.0|            372.05|                 0|             3.12|               8.0|       NULL|             44.12|\n",
      "|    50%|                   31.0|            600.84|                 1|             5.25|               9.0|       NULL|              48.6|\n",
      "|    75%|                   42.0|            844.01|                 1|              7.4|              14.0|       NULL|             70.58|\n",
      "|    max|                   60.0|            1330.5|                 1|             10.0|              15.0|   Zimbabwe|              75.0|\n",
      "+-------+-----------------------+------------------+------------------+-----------------+------------------+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Session_Connection_Time',\n",
       " 'Bytes Transferred',\n",
       " 'Kali_Trace_Used',\n",
       " 'Servers_Corrupted',\n",
       " 'Pages_Corrupted',\n",
       " 'Location',\n",
       " 'WPM_Typing_Speed']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a List of column names that represent features of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    'Session_Connection_Time',\n",
    "    'Bytes Transferred',\n",
    "    'Kali_Trace_Used',\n",
    "    'Servers_Corrupted',\n",
    " 'Pages_Corrupted',\n",
    " 'WPM_Typing_Speed'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Import The necessary modeules for Creating VectorAssembly \n",
    "\n",
    "2) Create a VectorAssembler to assemble selected columns into a feature vector \n",
    "\n",
    "3) Transform the DataFrame using the VectorAssembler to add the 'Features' column \n",
    "\n",
    "4) Print the schema of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Session_Connection_Time: double (nullable = true)\n",
      " |-- Bytes Transferred: double (nullable = true)\n",
      " |-- Kali_Trace_Used: integer (nullable = true)\n",
      " |-- Servers_Corrupted: double (nullable = true)\n",
      " |-- Pages_Corrupted: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- WPM_Typing_Speed: double (nullable = true)\n",
      " |-- Features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols,outputCol='Features')\n",
    "\n",
    "output_data = assembler.transform(df)\n",
    "\n",
    "output_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+--------------------+\n",
      "|Session_Connection_Time|Bytes Transferred|Kali_Trace_Used|Servers_Corrupted|Pages_Corrupted|            Location|WPM_Typing_Speed|            Features|\n",
      "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+--------------------+\n",
      "|                    8.0|           391.09|              1|             2.96|            7.0|            Slovenia|           72.37|[8.0,391.09,1.0,2...|\n",
      "|                   20.0|           720.99|              0|             3.04|            9.0|British Virgin Is...|           69.08|[20.0,720.99,0.0,...|\n",
      "|                   31.0|           356.32|              1|             3.71|            8.0|             Tokelau|           70.58|[31.0,356.32,1.0,...|\n",
      "|                    2.0|           228.08|              1|             2.48|            8.0|             Bolivia|            70.8|[2.0,228.08,1.0,2...|\n",
      "|                   20.0|            408.5|              0|             3.57|            8.0|                Iraq|           71.28|[20.0,408.5,0.0,3...|\n",
      "|                    1.0|           390.69|              1|             2.79|            9.0|    Marshall Islands|           71.57|[1.0,390.69,1.0,2...|\n",
      "|                   18.0|           342.97|              1|              5.1|            7.0|             Georgia|           72.32|[18.0,342.97,1.0,...|\n",
      "|                   22.0|           101.61|              1|             3.03|            7.0|         Timor-Leste|           72.03|[22.0,101.61,1.0,...|\n",
      "|                   15.0|           275.53|              1|             3.53|            8.0|Palestinian Terri...|           70.17|[15.0,275.53,1.0,...|\n",
      "|                   12.0|           424.83|              1|             2.53|            8.0|          Bangladesh|           69.99|[12.0,424.83,1.0,...|\n",
      "|                   15.0|           249.09|              1|             3.39|            9.0|Northern Mariana ...|           70.77|[15.0,249.09,1.0,...|\n",
      "|                   32.0|           242.48|              0|             4.24|            8.0|            Zimbabwe|           67.93|[32.0,242.48,0.0,...|\n",
      "|                   23.0|           514.54|              0|             3.18|            8.0|         Isle of Man|           68.56|[23.0,514.54,0.0,...|\n",
      "|                    9.0|           284.77|              0|             3.12|            9.0|Sao Tome and Prin...|           70.82|[9.0,284.77,0.0,3...|\n",
      "|                   27.0|           779.25|              1|             2.37|            8.0|              Greece|           72.73|[27.0,779.25,1.0,...|\n",
      "|                   12.0|           307.31|              1|             3.22|            7.0|     Solomon Islands|           67.95|[12.0,307.31,1.0,...|\n",
      "|                   21.0|           355.94|              1|              2.0|            7.0|       Guinea-Bissau|            72.0|[21.0,355.94,1.0,...|\n",
      "|                   10.0|           372.65|              0|             3.33|            7.0|        Burkina Faso|           69.19|[10.0,372.65,0.0,...|\n",
      "|                   20.0|           347.23|              1|             2.33|            7.0|            Mongolia|           70.41|[20.0,347.23,1.0,...|\n",
      "|                   22.0|           456.57|              0|             1.52|            8.0|             Nigeria|           69.35|[22.0,456.57,0.0,...|\n",
      "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre_Processing \n",
    "1)  Import the StandScaler class from the Pyspark MLLib library \n",
    "\n",
    "2) Create an instance of StandardScaler class \n",
    "- 'inputCol' specifies the input to scale ('Features' in this case)\n",
    "- 'outputCol' specifies the name of the output column ('Features_scaled' in this case)\n",
    "\n",
    "3) Fit the scaler to the 'output_dataset'\n",
    " - This computes summary statistics and prepares the scaler for transformation \n",
    "\n",
    "\n",
    "4) Tranform the 'output_dataset' using the fitted scaler\n",
    " - This scales the 'features' column and adds a new column 'features_scaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Session_Connection_Time=8.0, Bytes Transferred=391.09, Kali_Trace_Used=1, Servers_Corrupted=2.96, Pages_Corrupted=7.0, Location='Slovenia', WPM_Typing_Speed=72.37, Features=DenseVector([8.0, 391.09, 1.0, 2.96, 7.0, 72.37]), Features_scaled=DenseVector([0.5679, 1.3658, 1.9976, 1.2859, 2.2849, 5.3963])),\n",
       " Row(Session_Connection_Time=20.0, Bytes Transferred=720.99, Kali_Trace_Used=0, Servers_Corrupted=3.04, Pages_Corrupted=9.0, Location='British Virgin Islands', WPM_Typing_Speed=69.08, Features=DenseVector([20.0, 720.99, 0.0, 3.04, 9.0, 69.08]), Features_scaled=DenseVector([1.4196, 2.518, 0.0, 1.3206, 2.9378, 5.151])),\n",
       " Row(Session_Connection_Time=31.0, Bytes Transferred=356.32, Kali_Trace_Used=1, Servers_Corrupted=3.71, Pages_Corrupted=8.0, Location='Tokelau', WPM_Typing_Speed=70.58, Features=DenseVector([31.0, 356.32, 1.0, 3.71, 8.0, 70.58]), Features_scaled=DenseVector([2.2004, 1.2444, 1.9976, 1.6117, 2.6114, 5.2628])),\n",
       " Row(Session_Connection_Time=2.0, Bytes Transferred=228.08, Kali_Trace_Used=1, Servers_Corrupted=2.48, Pages_Corrupted=8.0, Location='Bolivia', WPM_Typing_Speed=70.8, Features=DenseVector([2.0, 228.08, 1.0, 2.48, 8.0, 70.8]), Features_scaled=DenseVector([0.142, 0.7965, 1.9976, 1.0774, 2.6114, 5.2792])),\n",
       " Row(Session_Connection_Time=20.0, Bytes Transferred=408.5, Kali_Trace_Used=0, Servers_Corrupted=3.57, Pages_Corrupted=8.0, Location='Iraq', WPM_Typing_Speed=71.28, Features=DenseVector([20.0, 408.5, 0.0, 3.57, 8.0, 71.28]), Features_scaled=DenseVector([1.4196, 1.4266, 0.0, 1.5509, 2.6114, 5.315]))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol= 'Features',\n",
    "                     outputCol = 'Features_scaled')\n",
    "\n",
    "\n",
    "scaler_fit_db = scaler.fit(output_data)\n",
    "\n",
    "\n",
    "scaler_trans_db  = scaler_fit_db.transform(output_data)\n",
    "scaler_trans_db.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+--------------------+--------------------+\n",
      "|Session_Connection_Time|Bytes Transferred|Kali_Trace_Used|Servers_Corrupted|Pages_Corrupted|            Location|WPM_Typing_Speed|            Features|     Features_scaled|\n",
      "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+--------------------+--------------------+\n",
      "|                    8.0|           391.09|              1|             2.96|            7.0|            Slovenia|           72.37|[8.0,391.09,1.0,2...|[0.56785108466505...|\n",
      "|                   20.0|           720.99|              0|             3.04|            9.0|British Virgin Is...|           69.08|[20.0,720.99,0.0,...|[1.41962771166263...|\n",
      "|                   31.0|           356.32|              1|             3.71|            8.0|             Tokelau|           70.58|[31.0,356.32,1.0,...|[2.20042295307707...|\n",
      "|                    2.0|           228.08|              1|             2.48|            8.0|             Bolivia|            70.8|[2.0,228.08,1.0,2...|[0.14196277116626...|\n",
      "|                   20.0|            408.5|              0|             3.57|            8.0|                Iraq|           71.28|[20.0,408.5,0.0,3...|[1.41962771166263...|\n",
      "|                    1.0|           390.69|              1|             2.79|            9.0|    Marshall Islands|           71.57|[1.0,390.69,1.0,2...|[0.07098138558313...|\n",
      "|                   18.0|           342.97|              1|              5.1|            7.0|             Georgia|           72.32|[18.0,342.97,1.0,...|[1.27766494049636...|\n",
      "|                   22.0|           101.61|              1|             3.03|            7.0|         Timor-Leste|           72.03|[22.0,101.61,1.0,...|[1.56159048282889...|\n",
      "|                   15.0|           275.53|              1|             3.53|            8.0|Palestinian Terri...|           70.17|[15.0,275.53,1.0,...|[1.06472078374697...|\n",
      "|                   12.0|           424.83|              1|             2.53|            8.0|          Bangladesh|           69.99|[12.0,424.83,1.0,...|[0.85177662699757...|\n",
      "|                   15.0|           249.09|              1|             3.39|            9.0|Northern Mariana ...|           70.77|[15.0,249.09,1.0,...|[1.06472078374697...|\n",
      "|                   32.0|           242.48|              0|             4.24|            8.0|            Zimbabwe|           67.93|[32.0,242.48,0.0,...|[2.27140433866020...|\n",
      "|                   23.0|           514.54|              0|             3.18|            8.0|         Isle of Man|           68.56|[23.0,514.54,0.0,...|[1.63257186841202...|\n",
      "|                    9.0|           284.77|              0|             3.12|            9.0|Sao Tome and Prin...|           70.82|[9.0,284.77,0.0,3...|[0.63883247024818...|\n",
      "|                   27.0|           779.25|              1|             2.37|            8.0|              Greece|           72.73|[27.0,779.25,1.0,...|[1.91649741074455...|\n",
      "|                   12.0|           307.31|              1|             3.22|            7.0|     Solomon Islands|           67.95|[12.0,307.31,1.0,...|[0.85177662699757...|\n",
      "|                   21.0|           355.94|              1|              2.0|            7.0|       Guinea-Bissau|            72.0|[21.0,355.94,1.0,...|[1.49060909724576...|\n",
      "|                   10.0|           372.65|              0|             3.33|            7.0|        Burkina Faso|           69.19|[10.0,372.65,0.0,...|[0.70981385583131...|\n",
      "|                   20.0|           347.23|              1|             2.33|            7.0|            Mongolia|           70.41|[20.0,347.23,1.0,...|[1.41962771166263...|\n",
      "|                   22.0|           456.57|              0|             1.52|            8.0|             Nigeria|           69.35|[22.0,456.57,0.0,...|[1.56159048282889...|\n",
      "+-----------------------+-----------------+---------------+-----------------+---------------+--------------------+----------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler_trans_db.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the Optimum Number of Clusters \n",
    "\n",
    "1) Import the K-means Class from the Pyspark Mlib Library \n",
    "\n",
    "2) Create a Kmean model with 'Features scaled' as the feature column and 'k' clusters set to 2\n",
    "\n",
    "3) Create a Kmean model with 'Features scaled' as the feature column and 'k' clusters set to 3\n",
    "\n",
    "4) Fit the first Kmean (kmeans1) to the 'scaler_trans_db' dataset\n",
    "\n",
    "5) Fit the second Kmean model (kmeans2) to the 'scaler_trans_db' dataset \n",
    "\n",
    "6) Get the transing cost (inertia) for the first Kmeans model.\n",
    "The training cost is a measure  of the sum of sqaured distances from each point to its assigned cluster center \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/10/28 09:46:25 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "601.7707512676691"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans \n",
    "\n",
    "kmeans1 = KMeans(featuresCol='Features_scaled',k=2)\n",
    "\n",
    "kmeans2 = KMeans(featuresCol='Features_scaled', k=3)\n",
    "\n",
    "model_1 = kmeans1.fit(scaler_trans_db)\n",
    "\n",
    "model_2 = kmeans2.fit(scaler_trans_db)\n",
    "\n",
    "\n",
    "model_1.summary.trainingCost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434.1492898715821"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_cost_2 = model_2.summary.trainingCost\n",
    "model_2.summary.trainingCost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the first K-mean (model_1) to make predictions on the 'scaler_trans_db' dataset.\n",
    "The resulting DataFrame contains a 'prediction' column indicating the cluster assignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1|  167|\n",
      "|         0|  167|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre = model_1.transform(scaler_trans_db).select('prediction')\n",
    "\n",
    "pre.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1|  167|\n",
      "|         2|   83|\n",
      "|         0|   84|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre = model_2.transform(scaler_trans_db).select('prediction')\n",
    "\n",
    "pre.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing definitive can be said with the above, but the last key fact that the engineer mentioned was that the attacks should be evenly numbered between the hackers! Let's check with the transform and prediction columns that result form this!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was 2 hackers. In fact, our clustering algorithm created two equally sized clusters with K=2, no way that is a coincidence!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
